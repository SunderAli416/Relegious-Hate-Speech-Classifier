{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"r4xn3Kon9Bjh"},"source":["# **Word level Embedding**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40542,"status":"ok","timestamp":1682978829140,"user":{"displayName":"Nawshrvan Arshad","userId":"03868594228693300325"},"user_tz":-300},"id":"pRSf7JifYNB6","outputId":"35426c6f-5bb4-4d84-cb77-b7e71c59b024"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]},{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}],"source":["import nltk\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","import pandas as pd\n","import pickle\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder as le\n","import tensorflow as tf\n","from sklearn.metrics import confusion_matrix,classification_report\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from tensorflow.keras import layers\n","from gensim.models import KeyedVectors"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B0qjE3Sl6Edf"},"outputs":[],"source":["df = pd.read_csv('/Data/train_data.csv')\n","df.columns\n","df['label'] = df['label'].replace({\"hate\":0,\"nothate\":1})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RpaGsoVS6Ki-"},"outputs":[],"source":["def preprocess_text(df):\n","  df['text'] = df['text'].apply(lambda x: x.lower())\n","  df['tokens'] = df['text'].apply(lambda x: nltk.word_tokenize(x))\n","  df['tokens'] = df['tokens'].apply(lambda x: [word for word in x if word.isalnum()])\n","  stop_words = set(nltk.corpus.stopwords.words('english'))\n","  df['tokens'] = df['tokens'].apply(lambda x: [word for word in x if not word in stop_words])\n","  stemmer = nltk.stem.PorterStemmer()\n","  df['tokens'] = df['tokens'].apply(lambda x: [stemmer.stem(word) for word in x])\n","  df['processed_text'] = df['tokens'].apply(lambda x: ' '.join(x))\n","  return df['processed_text']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wi9V5MyfwHCO"},"outputs":[],"source":["max_length = 50\n","embedding_dim = 50\n","num_words = 2624"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["\n","\n","The below code snippet performs the following steps:\n","\n","1. It loads the word vectors from the GloVe file using the `KeyedVectors` class from the `gensim` library. The GloVe file path is provided as `glove_file`.\n","2. It preprocesses the text in the `df` DataFrame and stores the processed text in a new column named `'processed_text'`.\n","3. It initializes a `Tokenizer` object `tokenizer`.\n","4. It fits the tokenizer on the `'processed_text'` column values of the `df` DataFrame.\n","5. It converts the text sequences in the `'processed_text'` column of the `df` DataFrame to sequences of integers using `texts_to_sequences`.\n","6. It pads the sequences in `sequences` using `pad_sequences`, specifying `maxlen`, `padding`, and `truncating` parameters. The resulting padded sequences are stored in `padded_sequences`.\n","7. It saves the `tokenizer` object to a pickle file named `'word_level_tokenizer.pickle'` using `pickle.dump`.\n","8. It retrieves the word index from the `tokenizer` object.\n","9. It calculates the number of words by adding 1 to the length of the `word_index`.\n","10. It initializes an embedding matrix with zeros of shape `(num_words, embedding_dim)`.\n","11. It iterates over the word index items.\n","   - If a word is present in the loaded word vectors, it assigns the corresponding word vector to the corresponding row in the embedding matrix.\n","12. The resulting embedding matrix is now ready to be used in the model.\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9IGdw3z06WOw"},"outputs":[],"source":["glove_file = '/Models/glove.6B.50d.txt'\n","word_vectors = KeyedVectors.load_word2vec_format(glove_file, binary=False)\n","\n","df['processed_text'] = preprocess_text(df)\n","\n","tokenizer = tf.keras.preprocessing.text.Tokenizer()\n","tokenizer.fit_on_texts(df['processed_text'])\n","sequences = tokenizer.texts_to_sequences(df['processed_text'])\n","padded_sequences = tf.keras.preprocessing.sequence.pad_sequences(\n","    sequences, maxlen=max_length, padding='post', truncating='post'\n",")\n","\n","with open('/Models/WordLevel/word_level_tokenizer.pickle', 'wb') as handle:\n","    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","word_index = tokenizer.word_index\n","num_words = len(word_index) + 1\n","# print(num_words)\n","embedding_matrix = np.zeros((num_words, embedding_dim))\n","for word, i in word_index.items():\n","    if word in word_vectors:\n","        embedding_matrix[i] = word_vectors[word]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":780,"status":"ok","timestamp":1682978872459,"user":{"displayName":"Nawshrvan Arshad","userId":"03868594228693300325"},"user_tz":-300},"id":"Xjc0hORU1m2d","outputId":"6944ad0e-296c-472b-c202-63a5e80974e5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Average sentence length: 53.789280958721704\n"]}],"source":["sentence_lengths = df['processed_text'].apply(lambda x: [len(x) for x in df['processed_text']])\n","avg_sentence_length = sentence_lengths.apply(lambda x: sum(x) / len(x))\n","print(\"Average sentence length:\", avg_sentence_length.mean())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vc_P9SNlZK80"},"outputs":[],"source":["checkpoint_filepath = '/Models/WordLevel/wordlevel_3000.h5'\n","checkpoint_callback = ModelCheckpoint(\n","    filepath=checkpoint_filepath,\n","    monitor='val_accuracy',\n","    mode='max',\n","    save_best_only=True,\n","    verbose=1\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":86773,"status":"ok","timestamp":1682978959228,"user":{"displayName":"Nawshrvan Arshad","userId":"03868594228693300325"},"user_tz":-300},"id":"kHooP2X_ided","outputId":"14f3991c-e504-453f-ac00-38d5f9d8cef8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","85/85 [==============================] - 11s 11ms/step - loss: 3.1680 - accuracy: 0.6807 - val_loss: 1.1320 - val_accuracy: 0.7475\n","Epoch 2/100\n","85/85 [==============================] - 1s 7ms/step - loss: 0.7396 - accuracy: 0.8139 - val_loss: 0.5909 - val_accuracy: 0.8106\n","Epoch 3/100\n","85/85 [==============================] - 1s 7ms/step - loss: 0.4264 - accuracy: 0.8801 - val_loss: 0.5368 - val_accuracy: 0.8140\n","Epoch 4/100\n","85/85 [==============================] - 1s 7ms/step - loss: 0.3101 - accuracy: 0.9101 - val_loss: 0.5639 - val_accuracy: 0.8239\n","Epoch 5/100\n","85/85 [==============================] - 1s 7ms/step - loss: 0.2506 - accuracy: 0.9271 - val_loss: 0.5574 - val_accuracy: 0.8239\n","Epoch 6/100\n","85/85 [==============================] - 1s 7ms/step - loss: 0.1949 - accuracy: 0.9523 - val_loss: 0.4598 - val_accuracy: 0.8472\n","Epoch 7/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.1622 - accuracy: 0.9630 - val_loss: 0.5841 - val_accuracy: 0.8472\n","Epoch 8/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.1172 - accuracy: 0.9804 - val_loss: 0.6900 - val_accuracy: 0.8306\n","Epoch 9/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.1201 - accuracy: 0.9756 - val_loss: 0.6884 - val_accuracy: 0.8339\n","Epoch 10/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.1423 - accuracy: 0.9686 - val_loss: 0.6084 - val_accuracy: 0.8306\n","Epoch 11/100\n","85/85 [==============================] - 0s 6ms/step - loss: 0.0933 - accuracy: 0.9841 - val_loss: 0.6202 - val_accuracy: 0.8605\n","Epoch 12/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0783 - accuracy: 0.9874 - val_loss: 0.7198 - val_accuracy: 0.8439\n","Epoch 13/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0796 - accuracy: 0.9871 - val_loss: 0.7119 - val_accuracy: 0.8439\n","Epoch 14/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0707 - accuracy: 0.9889 - val_loss: 0.6920 - val_accuracy: 0.8538\n","Epoch 15/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0662 - accuracy: 0.9889 - val_loss: 0.7815 - val_accuracy: 0.8372\n","Epoch 16/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0705 - accuracy: 0.9878 - val_loss: 0.6995 - val_accuracy: 0.8439\n","Epoch 17/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0593 - accuracy: 0.9904 - val_loss: 0.8106 - val_accuracy: 0.8405\n","Epoch 18/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0495 - accuracy: 0.9933 - val_loss: 0.6544 - val_accuracy: 0.8505\n","Epoch 19/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0491 - accuracy: 0.9930 - val_loss: 0.6231 - val_accuracy: 0.8538\n","Epoch 20/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.1018 - accuracy: 0.9797 - val_loss: 0.7178 - val_accuracy: 0.8505\n","Epoch 21/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0972 - accuracy: 0.9815 - val_loss: 0.7488 - val_accuracy: 0.8571\n","Epoch 22/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0586 - accuracy: 0.9904 - val_loss: 0.7238 - val_accuracy: 0.8638\n","Epoch 23/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0499 - accuracy: 0.9919 - val_loss: 0.7991 - val_accuracy: 0.8538\n","Epoch 24/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0438 - accuracy: 0.9937 - val_loss: 0.7777 - val_accuracy: 0.8272\n","Epoch 25/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0438 - accuracy: 0.9933 - val_loss: 0.8215 - val_accuracy: 0.8538\n","Epoch 26/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0386 - accuracy: 0.9945 - val_loss: 0.7129 - val_accuracy: 0.8571\n","Epoch 27/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0350 - accuracy: 0.9937 - val_loss: 0.7332 - val_accuracy: 0.8472\n","Epoch 28/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0339 - accuracy: 0.9941 - val_loss: 0.7479 - val_accuracy: 0.8538\n","Epoch 29/100\n","85/85 [==============================] - 0s 6ms/step - loss: 0.0356 - accuracy: 0.9937 - val_loss: 0.7189 - val_accuracy: 0.8538\n","Epoch 30/100\n","85/85 [==============================] - 1s 7ms/step - loss: 0.0347 - accuracy: 0.9937 - val_loss: 0.7650 - val_accuracy: 0.8638\n","Epoch 31/100\n","85/85 [==============================] - 1s 7ms/step - loss: 0.0399 - accuracy: 0.9937 - val_loss: 0.7641 - val_accuracy: 0.8571\n","Epoch 32/100\n","85/85 [==============================] - 1s 7ms/step - loss: 0.0351 - accuracy: 0.9948 - val_loss: 0.9295 - val_accuracy: 0.8472\n","Epoch 33/100\n","85/85 [==============================] - 1s 7ms/step - loss: 0.0364 - accuracy: 0.9922 - val_loss: 0.8620 - val_accuracy: 0.8272\n","Epoch 34/100\n","85/85 [==============================] - 1s 7ms/step - loss: 0.0515 - accuracy: 0.9889 - val_loss: 0.8406 - val_accuracy: 0.8505\n","Epoch 35/100\n","85/85 [==============================] - 0s 6ms/step - loss: 0.1552 - accuracy: 0.9597 - val_loss: 0.7281 - val_accuracy: 0.8339\n","Epoch 36/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.1029 - accuracy: 0.9826 - val_loss: 0.6499 - val_accuracy: 0.8571\n","Epoch 37/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0994 - accuracy: 0.9763 - val_loss: 0.9943 - val_accuracy: 0.8206\n","Epoch 38/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0687 - accuracy: 0.9856 - val_loss: 0.8308 - val_accuracy: 0.8306\n","Epoch 39/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0391 - accuracy: 0.9952 - val_loss: 0.8600 - val_accuracy: 0.8173\n","Epoch 40/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0351 - accuracy: 0.9937 - val_loss: 0.9341 - val_accuracy: 0.8605\n","Epoch 41/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0305 - accuracy: 0.9945 - val_loss: 0.8444 - val_accuracy: 0.8272\n","Epoch 42/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0303 - accuracy: 0.9941 - val_loss: 0.8352 - val_accuracy: 0.8405\n","Epoch 43/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0302 - accuracy: 0.9948 - val_loss: 0.8194 - val_accuracy: 0.8638\n","Epoch 44/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0296 - accuracy: 0.9952 - val_loss: 0.8439 - val_accuracy: 0.8605\n","Epoch 45/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0319 - accuracy: 0.9937 - val_loss: 0.8823 - val_accuracy: 0.8571\n","Epoch 46/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0281 - accuracy: 0.9959 - val_loss: 0.8855 - val_accuracy: 0.8571\n","Epoch 47/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0289 - accuracy: 0.9937 - val_loss: 1.0438 - val_accuracy: 0.8571\n","Epoch 48/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0283 - accuracy: 0.9933 - val_loss: 0.9434 - val_accuracy: 0.8505\n","Epoch 49/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0252 - accuracy: 0.9948 - val_loss: 0.8454 - val_accuracy: 0.8538\n","Epoch 50/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0275 - accuracy: 0.9952 - val_loss: 0.8691 - val_accuracy: 0.8538\n","Epoch 51/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0369 - accuracy: 0.9933 - val_loss: 0.9213 - val_accuracy: 0.8472\n","Epoch 52/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0354 - accuracy: 0.9937 - val_loss: 0.9819 - val_accuracy: 0.8239\n","Epoch 53/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.1036 - accuracy: 0.9745 - val_loss: 0.9240 - val_accuracy: 0.8339\n","Epoch 54/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0863 - accuracy: 0.9804 - val_loss: 1.0460 - val_accuracy: 0.8472\n","Epoch 55/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0440 - accuracy: 0.9926 - val_loss: 1.0569 - val_accuracy: 0.8372\n","Epoch 56/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0346 - accuracy: 0.9948 - val_loss: 1.0348 - val_accuracy: 0.8339\n","Epoch 57/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0571 - accuracy: 0.9852 - val_loss: 1.1598 - val_accuracy: 0.8140\n","Epoch 58/100\n","85/85 [==============================] - 1s 7ms/step - loss: 0.1029 - accuracy: 0.9767 - val_loss: 0.9830 - val_accuracy: 0.8339\n","Epoch 59/100\n","85/85 [==============================] - 1s 7ms/step - loss: 0.0683 - accuracy: 0.9878 - val_loss: 0.9538 - val_accuracy: 0.8505\n","Epoch 60/100\n","85/85 [==============================] - 1s 7ms/step - loss: 0.0445 - accuracy: 0.9930 - val_loss: 0.8993 - val_accuracy: 0.8605\n","Epoch 61/100\n","85/85 [==============================] - 1s 8ms/step - loss: 0.0339 - accuracy: 0.9952 - val_loss: 1.0409 - val_accuracy: 0.8538\n","Epoch 62/100\n","85/85 [==============================] - 1s 8ms/step - loss: 0.0314 - accuracy: 0.9933 - val_loss: 0.9942 - val_accuracy: 0.8505\n","Epoch 63/100\n","85/85 [==============================] - 1s 7ms/step - loss: 0.0285 - accuracy: 0.9937 - val_loss: 0.9692 - val_accuracy: 0.8571\n","Epoch 64/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0248 - accuracy: 0.9945 - val_loss: 1.1376 - val_accuracy: 0.8372\n","Epoch 65/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0245 - accuracy: 0.9959 - val_loss: 1.0740 - val_accuracy: 0.8505\n","Epoch 66/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0226 - accuracy: 0.9970 - val_loss: 1.0985 - val_accuracy: 0.8505\n","Epoch 67/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0275 - accuracy: 0.9948 - val_loss: 0.9608 - val_accuracy: 0.8439\n","Epoch 68/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0252 - accuracy: 0.9941 - val_loss: 0.8959 - val_accuracy: 0.8405\n","Epoch 69/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0234 - accuracy: 0.9956 - val_loss: 0.9726 - val_accuracy: 0.8638\n","Epoch 70/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0240 - accuracy: 0.9956 - val_loss: 0.9727 - val_accuracy: 0.8439\n","Epoch 71/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0221 - accuracy: 0.9959 - val_loss: 0.9893 - val_accuracy: 0.8472\n","Epoch 72/100\n","85/85 [==============================] - 0s 6ms/step - loss: 0.0252 - accuracy: 0.9937 - val_loss: 1.0173 - val_accuracy: 0.8206\n","Epoch 73/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0653 - accuracy: 0.9885 - val_loss: 1.3649 - val_accuracy: 0.8306\n","Epoch 74/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0850 - accuracy: 0.9834 - val_loss: 1.0921 - val_accuracy: 0.8306\n","Epoch 75/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0696 - accuracy: 0.9845 - val_loss: 1.0404 - val_accuracy: 0.8239\n","Epoch 76/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0550 - accuracy: 0.9922 - val_loss: 1.0847 - val_accuracy: 0.8339\n","Epoch 77/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0597 - accuracy: 0.9874 - val_loss: 1.0523 - val_accuracy: 0.8272\n","Epoch 78/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0523 - accuracy: 0.9893 - val_loss: 1.2041 - val_accuracy: 0.8206\n","Epoch 79/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0449 - accuracy: 0.9908 - val_loss: 1.1217 - val_accuracy: 0.8272\n","Epoch 80/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0396 - accuracy: 0.9904 - val_loss: 0.9874 - val_accuracy: 0.8239\n","Epoch 81/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0484 - accuracy: 0.9915 - val_loss: 1.3859 - val_accuracy: 0.8339\n","Epoch 82/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0774 - accuracy: 0.9815 - val_loss: 0.9887 - val_accuracy: 0.8206\n","Epoch 83/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0515 - accuracy: 0.9915 - val_loss: 0.9391 - val_accuracy: 0.8339\n","Epoch 84/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0330 - accuracy: 0.9945 - val_loss: 1.0465 - val_accuracy: 0.8372\n","Epoch 85/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0286 - accuracy: 0.9945 - val_loss: 1.0771 - val_accuracy: 0.8339\n","Epoch 86/100\n","85/85 [==============================] - 1s 7ms/step - loss: 0.0253 - accuracy: 0.9941 - val_loss: 1.1719 - val_accuracy: 0.8239\n","Epoch 87/100\n","85/85 [==============================] - 1s 7ms/step - loss: 0.0221 - accuracy: 0.9952 - val_loss: 1.1137 - val_accuracy: 0.8405\n","Epoch 88/100\n","85/85 [==============================] - 1s 7ms/step - loss: 0.0208 - accuracy: 0.9967 - val_loss: 0.9665 - val_accuracy: 0.8505\n","Epoch 89/100\n","85/85 [==============================] - 1s 8ms/step - loss: 0.0221 - accuracy: 0.9952 - val_loss: 0.9952 - val_accuracy: 0.8439\n","Epoch 90/100\n","85/85 [==============================] - 1s 7ms/step - loss: 0.0252 - accuracy: 0.9933 - val_loss: 1.1117 - val_accuracy: 0.8472\n","Epoch 91/100\n","85/85 [==============================] - 1s 7ms/step - loss: 0.0237 - accuracy: 0.9941 - val_loss: 1.0949 - val_accuracy: 0.8306\n","Epoch 92/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0490 - accuracy: 0.9885 - val_loss: 1.4210 - val_accuracy: 0.8405\n","Epoch 93/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0724 - accuracy: 0.9885 - val_loss: 0.9668 - val_accuracy: 0.8405\n","Epoch 94/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0354 - accuracy: 0.9956 - val_loss: 1.0358 - val_accuracy: 0.8439\n","Epoch 95/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0293 - accuracy: 0.9945 - val_loss: 0.9613 - val_accuracy: 0.8405\n","Epoch 96/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0262 - accuracy: 0.9948 - val_loss: 1.1235 - val_accuracy: 0.8306\n","Epoch 97/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0260 - accuracy: 0.9941 - val_loss: 1.0552 - val_accuracy: 0.8372\n","Epoch 98/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0238 - accuracy: 0.9937 - val_loss: 1.0300 - val_accuracy: 0.8405\n","Epoch 99/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0218 - accuracy: 0.9956 - val_loss: 1.0739 - val_accuracy: 0.8372\n","Epoch 100/100\n","85/85 [==============================] - 0s 5ms/step - loss: 0.0211 - accuracy: 0.9959 - val_loss: 0.9841 - val_accuracy: 0.8405\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7f367813a380>"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["model = tf.keras.models.Sequential([\n","    layers.Embedding(num_words, embedding_dim, embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n","                    input_length=max_length, trainable=False),\n","    tf.keras.layers.Conv1D(128, 5, activation='relu'),\n","    tf.keras.layers.MaxPooling1D(pool_size=4),\n","    tf.keras.layers.Conv1D(256, 5, activation='relu'),\n","    tf.keras.layers.MaxPooling1D(pool_size=4),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n","    tf.keras.layers.Dropout(0.5),\n","    tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n","    tf.keras.layers.Dropout(0.5),\n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","])\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","model.fit(padded_sequences, df['label'], epochs = 100, validation_split = 0.1,callbacks=[checkpoint_callback])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z84y22QVZnx9"},"outputs":[],"source":["with open('/Models/WordLevel/word_level_tokenizer.pickle', 'rb') as handle:\n","    loaded_tokenizer = pickle.load(handle)\n","\n","loaded_model = load_model('/Models/WordLevel/wordlevel_3000.h5')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["\n","\n","The below code snippet defines and trains a sequential model for text classification:\n","\n","1. It initializes a sequential model using `tf.keras.models.Sequential()`.\n","2. It adds an embedding layer to the model using `layers.Embedding` with the following parameters:\n","   - `num_words`: The number of words in the vocabulary.\n","   - `embedding_dim`: The dimensionality of the word embeddings.\n","   - `embeddings_initializer`: The initializer for the embedding matrix, which is set to the pre-trained `embedding_matrix`.\n","   - `input_length`: The length of input sequences, set to `max_length`.\n","   - `trainable`: The embedding layer is set to be non-trainable by setting `trainable=False`.\n","3. It adds a 1D convolutional layer with 128 filters and a kernel size of 5, followed by a ReLU activation function.\n","4. It adds a max pooling layer with a pool size of 4.\n","5. It adds another 1D convolutional layer with 256 filters and a kernel size of 5, followed by a ReLU activation function.\n","6. It adds another max pooling layer with a pool size of 4.\n","7. It adds a flatten layer to convert the 3D tensor to a 2D tensor.\n","8. It adds a dense layer with 512 units, a ReLU activation function, and L2 regularization with a coefficient of 0.01.\n","9. It adds a dropout layer with a rate of 0.5 to prevent overfitting.\n","10. It adds another dense layer with 256 units, a ReLU activation function, and L2 regularization with a coefficient of 0.01.\n","11. It adds another dropout layer with a rate of 0.5.\n","12. It adds a final dense layer with 1 unit and a sigmoid activation function for binary classification.\n","13. It compiles the model with the Adam optimizer, binary cross-entropy loss function, and accuracy metric.\n","14. It trains the model on the `padded_sequences` input data and `df['label']` target labels for 100 epochs, with a validation split of 0.1.\n","15. It uses a checkpoint callback for model saving during training.\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xR7JHj1rw6UC","outputId":"8cfd8063-806b-4906-d18e-1255dbb5ce2e"},"outputs":[{"name":"stdout","output_type":"stream","text":["11/11 [==============================] - 1s 27ms/step\n","11/11 [==============================] - 1s 15ms/step - loss: 0.6660 - accuracy: 0.8892\n","Test loss: 0.6659772992134094\n","Test accuracy: 0.8892215490341187\n","\n","[[167  22]\n"," [ 15 130]]\n","              precision    recall  f1-score   support\n","\n","           0       0.92      0.88      0.90       189\n","           1       0.86      0.90      0.88       145\n","\n","    accuracy                           0.89       334\n","   macro avg       0.89      0.89      0.89       334\n","weighted avg       0.89      0.89      0.89       334\n","\n"]}],"source":["df2 = pd.read_csv('/Data/test_data.csv')\n","df2['label'] = df2['label'].replace({\"hate\":0,\"nothate\":1})\n","\n","df2['processed_text'] = preprocess_text(df2)\n","\n","test_sequences = loaded_tokenizer.texts_to_sequences(df2['processed_text'])\n","test_data_padded = tf.keras.preprocessing.sequence.pad_sequences(test_sequences, maxlen=max_length, padding='post', truncating='post')\n","\n","pred = loaded_model.predict(test_data_padded)\n","loss, acc = loaded_model.evaluate(test_data_padded,df2['label'], batch_size=32)\n","\n","print('Test loss:', loss)\n","print('Test accuracy:', acc,end = '\\n\\n')\n","\n","for i,x in enumerate(pred):#['hate = 0' 'nothate = 1']\n","  if x >= 0.5:\n","    pred[i] = 1\n","  else:\n","    pred[i] = 0\n","cm = confusion_matrix(df2['label'],pred)\n","print(cm)\n","cr = classification_report(df2['label'],pred)\n","print(cr)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
